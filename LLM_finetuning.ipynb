{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sit-xinli/ai-course5/blob/main/LLM_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh5rwbr4q5Nw"
      },
      "source": [
        "## LLM fine tunning\n",
        "LLMが唐詩を書けるように、あなたのLLMを微調整します。.\n",
        "\n",
        "**TODOs**\n",
        "1. スライドを読み、この宿題の目的を確認してください。\n",
        "2. このColabノートをコピーして保存してください。\n",
        "3. このColabノートの手順に従って、LLMを微調整する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRKf5DA69b3r"
      },
      "source": [
        "## GPUをアクティブにする\n",
        "\n",
        "モデルを微調整するので、この宿題が妥当な時間（1～2時間）でできるように、GPUをアクティブにする必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrXWZefE-WXJ"
      },
      "source": [
        "## グーグルドライブをマウントする\n",
        "Googleドライブに結果を保存できるように、Googleドライブをマウントする必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8cXGoOcCLrK"
      },
      "source": [
        "以下のコードブロックの実行時間は約***1分**ですが、ColabとGoogle Driveの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4irqfznNAlrZ",
        "outputId": "4510c6cb-93cb-4ae8-cc34-9a8aa807591c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hJFrdFQn84M"
      },
      "source": [
        "## パッケージのインストール\n",
        "私たちは、微調整を容易にするために、他の人が作成したよくできたパッケージをインストールし、インポートします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UoAVpcAELzB"
      },
      "source": [
        "以下のコードブロックの実行にかかる時間は約 **5**分ですが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuRMjk0rtWBx",
        "outputId": "3a7996fc-33fd-4eae-acc1-b60bbfe9a772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.7.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "!pip install bitsandbytes\n",
        "!pip install transformers\n",
        "!pip install peft\n",
        "!pip install sentencepiece\n",
        "!pip install colorama\n",
        "!pip install fsspec==2025.3.0\n",
        "!pip install -U datasets\n",
        "!pip install -U accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OMmuIblEXiU"
      },
      "source": [
        "以下のコードブロックの実行時間は約**20**秒ですが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVVG_SQrvFpe"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import json\n",
        "import warnings\n",
        "import logging\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import transformers, datasets\n",
        "from peft import PeftModel\n",
        "from colorama import *\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from transformers import GenerationConfig\n",
        "from peft import (\n",
        "    #prepare_model_for_int8_training,\n",
        "    prepare_model_for_kbit_training,\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    prepare_model_for_kbit_training\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCo1znQhpBdt"
      },
      "source": [
        "## 微調整用データセットのダウンロード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESzwsaT9poC4"
      },
      "source": [
        "## ランダムシードを修正する\n",
        "ファインチューニングのプロセスには、結果の再現性を高めるためにランダムシードを固定する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37Ra-OARteHI"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "seed = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTaVpMgzp3oC"
      },
      "source": [
        "## 便利な関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKjoLO3xtfM1"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "# トレーニングデータの作成\n",
        "def generate_training_data(data_point):\n",
        "    \"\"\"\n",
        "    (1) 目的\n",
        "        - この関数は、データポイント（入力テキストと出力テキスト）を、モデルが読み取れるトークンに変換するために使用される。\n",
        "    (2) 引数\n",
        "        - data_point: dict。フィールドは \"instruction\"、\"input\"、\"output\"。\n",
        "    (3) 返り値\n",
        "        - モデルの入力トークン、モデルを因果的にするアテンションマスク、対応する出力ターゲットを持つdict\n",
        "    (3) 例：\n",
        "        - フィールド \"instruction\"、\"input\"、\"output \"がすべてstrであるdict、data_point_1を作成した場合、この関数は次のように使うことができる：\n",
        "            formulate_article(データ_point_1)\n",
        "    \"\"\"\n",
        "    # construct full input prompt\n",
        "    prompt = f\"\"\"\\\n",
        "[INST] <<SYS>>\n",
        "あなたは親切なアシスタントだし、唐詩を書くこともうまい。\n",
        "<</SYS>>\n",
        "\n",
        "{data_point[\"instruction\"]}\n",
        "{data_point[\"input\"]}\n",
        "[/INST]\"\"\"\n",
        "\n",
        "    # count the number of input tokens\n",
        "    len_user_prompt_tokens = (\n",
        "        len(\n",
        "            tokenizer(\n",
        "                prompt,\n",
        "                truncation=True,\n",
        "                max_length=CUTOFF_LEN + 1,\n",
        "                padding=\"max_length\",\n",
        "            )[\"input_ids\"]\n",
        "        ) - 1\n",
        "    )\n",
        "    # transform input prompt into tokens\n",
        "    full_tokens = tokenizer(\n",
        "        prompt + \" \" + data_point[\"output\"] + \"</s>\",\n",
        "        truncation=True,\n",
        "        max_length=CUTOFF_LEN + 1,\n",
        "        padding=\"max_length\",\n",
        "    )[\"input_ids\"][:-1]\n",
        "    return {\n",
        "        \"input_ids\": full_tokens,\n",
        "        \"labels\": [-100] * len_user_prompt_tokens\n",
        "        + full_tokens[len_user_prompt_tokens:],\n",
        "        \"attention_mask\": [1] * (len(full_tokens)),\n",
        "    }\n",
        "\n",
        "# 生成された回答の評価\n",
        "def evaluate(instruction, generation_config, max_len, input=\"\", verbose=True):\n",
        "    \"\"\"\n",
        "    (1) 目標\n",
        "        - この関数は、与えられた入力文字列からモデルの出力を得るために使われる。\n",
        "\n",
        "    (2) 引数：\n",
        "        - instruction: str, モデルに何をさせたいかの説明。\n",
        "        - generation_config: transformers.GenerationConfigオブジェクト、モデルの推論に関連するデコードパラメータを指定する。\n",
        "        - max_len: int, モデルの出力の最大長。\n",
        "        - input: str, モデルが命令を解くために必要な入力文字列、デフォルトは\"\"(入力なし)\n",
        "        - verbose: bool, モードの出力を表示するかどうか、デフォルトはTrue\n",
        "    (3) 戻り値\n",
        "        - output: str, 命令と入力に従ったモードの応答\n",
        "    (4) 例\n",
        "        - 命令が \"ABC\"、入力が \"DEF \"で、128トークン以下の回答をモデルに与えたい場合、この関数を次のように使うことができる：\n",
        "            evaluate(instruction=\"ABC\", generation_config=generation_config, max_len=128, input=\"DEF\")\n",
        "\n",
        "    \"\"\"\n",
        "    # construct full input prompt\n",
        "    prompt = f\"\"\"\\\n",
        "[INST] <<SYS>>\n",
        "あなたは親切なアシスタントだし、唐詩を書くこともうまい。\n",
        "<</SYS>>\n",
        "\n",
        "{instruction}\n",
        "{input}\n",
        "[/INST]\"\"\"\n",
        "    # プロンプトのテキストをモデルが必要とする数値表現に変換する。\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].cuda()\n",
        "    # モデルを使って返信を生成する\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=generation_config,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "        max_new_tokens=max_len,\n",
        "    )\n",
        "    # 生成された応答をデコードしてプリントアウトする。\n",
        "    for s in generation_output.sequences:\n",
        "        output = tokenizer.decode(s)\n",
        "        output = output.split(\"[/INST]\")[1].replace(\"</s>\", \"\").replace(\"<s>\", \"\").replace(\"Assistant:\", \"\").replace(\"Assistant\", \"\").strip()\n",
        "        if (verbose):\n",
        "            print(output)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNxuuclCqFf5"
      },
      "source": [
        "## 微調整前のモデルと推論をダウンロードする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmfEFM7TNuRC"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルトの設定を使用した場合、約 **10**分かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq6WXaBnxYq"
      },
      "source": [
        "## 微調整前の推論\n",
        "まず、ファインチューニングなしのモデルで何ができるかを見てみよう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox5QRpz4NiPg"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルトの設定を使用した場合、約2分**かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1sFQbHGn3Bw"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "model_name = \"Qwen/Qwen3-0.6B\" # 微調整に使用するモデルを設定する。\n",
        "cache_dir = \"./cache\"\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# 指定されたモデル名またはパスから，事前に学習された言語モデルを読み込みます．\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    cache_dir=cache_dir,\n",
        "    quantization_config=nf4_config,\n",
        "    low_cpu_mem_usage = True\n",
        ")\n",
        "\n",
        "# トークナイザーを作成し、終了シンボル(eos_token)を設定します。\n",
        "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    add_eos_token=True,\n",
        "    cache_dir=cache_dir,\n",
        "    #quantization_config=nf4_config\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# モデル推論のためのデコーディング・パラメータの設定\n",
        "max_len = 256\n",
        "generation_config = GenerationConfig(\n",
        "    do_sample=True,\n",
        "    temperature=0.1,\n",
        "    num_beams=1,\n",
        "    top_p=0.3,\n",
        "    no_repeat_ngram_size=3,\n",
        "    pad_token_id=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LyTYIcDOAkO"
      },
      "source": [
        "以下のコードブロックは、デフォルトの設定を使用した場合、実行に約 **1** 分かかりますが、Colab の状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJyuoPoO2TCr",
        "outputId": "cf7d86d7-2d51-40bf-b405-78ae64d2b4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。日本語以外に出力しない。\n",
            "\n",
            "会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。\n",
            "\n",
            "モデル出力:\n",
            "この唐詩は、詩の内容が「会って도別れの告げは難しい」「東風に力が」、そして「花は全て散ってしまった」です。この詩は東風の詩と相似である。東風は風の名前で、東風が風のことをいう。詩のテーマは「風の力」、つまり、風の力を有するもの。この唐诗は、風が散ったことを示しています。詩は「東風」を「風」にしたものです。詩には、東风が力があることを示している。詩では、東の風が力がなかったことを示っている。詩が「東风には力がない」という意味を示している。\n",
            "\n",
            "この唐ポは、東が風をもつものと示していること、東は風を無つものものと表していること。詩に「東の风」が「風」という名前をもっている。この诗は東の詩とも相似である。\n",
            "\n",
            "この詩の主なテーマは、「風が無力」を示しています。\n",
            "\n",
            "この诗の内容は、会って別れも告げられない、東 wind には力がある、花がすべて散\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。日本語以外に出力しない。\n",
            "\n",
            "重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。\n",
            "\n",
            "モデル出力:\n",
            "この詩は「重いのカーヤンの上に深い喪に着いていた」で、詩の内容は「夜の長さ」であります。  \n",
            "この唐詩は、詩に「重」、「深」、「夜」、「長」などの言葉が含まれています。\n",
            "\n",
            "この詩の文脈は、喪の夜のことをテーマにしています。  \n",
            "詩の主語は「喪」です。  \n",
            "「重」「深」「夜」「長」は詩の要素です。\n",
            "\n",
            "この唐诗は、夜の長いことをテーマとしている。  \n",
            "また、詩中には「重」という言葉も含まれています。  \n",
            "さらに、詩には「夜」が含まれている。  \n",
            "そして、詩は長さをテーマとしています。\n",
            "\n",
            "この诗は「長」をテーマにしている。  \n",
            "重いと深い夜の夜は長い。  \n",
            "夜の长さを示している。\n",
            "\n",
            "この诗歌的要素は「长」、「重」、「夜」「深」、 「喪」、 そして「長さ」とあります。\n",
            "\n",
            "この poem は「丧の夜」を主題にしています。\n",
            "\n",
            "詩のテーマは「葬礼」です。\n",
            "\n",
            "詩中で「喪」という意語\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。日本語以外に出力しない。\n",
            "\n",
            "逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。\n",
            "\n",
            "モデル出力:\n",
            "この詩は「逃亡」の果たに香りに星を、禁断園を驚きのものと述べている。  \n",
            "この唐詩は、詩の内容を日本語で簡潔にするために、  \n",
            "「香りと星」を「香」、「園」を、「驚き」を、  \n",
            "それぞれに「香の星」、 「園の園」、、「驚く」という表現にしたものです。  \n",
            "したがって、この詩の日本語版は「香と星が香の園の园に驚く」というものです。  \n",
            "\n",
            "この詩を日本语で簡約するには、  \n",
            "詩の文脈を日本字にした「香」と「星」、「園」、「驚」をそれぞれに  \n",
            "「の香」、「の星」「の園」という表現にしました。  \n",
            "すると、この唐诗は「のの香の园の園驚く」「のの星の香」「の的園の驚き」ということになります。  \n",
            "そして、この表現は、  \n",
            "この诗の内容が「逃びに追かえる香の香と、禁斷の園を惊く」  \n",
            "つまり、「香のの園が驚く\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "# demo examples\n",
        "test_tang_list = ['会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。',\n",
        "                  '重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。',\n",
        "                  '逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。']\n",
        "\n",
        "system_prompt = '以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。'\n",
        "\n",
        "# get the model output for each examples\n",
        "demo_before_finetune = []\n",
        "for tang in test_tang_list:\n",
        "  demo_before_finetune.append(f'モデル入力:\\n{system_prompt}\\n\\n{tang}\\n\\nモデル出力:\\n'+evaluate(system_prompt, generation_config, max_len, tang, verbose = False))\n",
        "\n",
        "# print and store the output to text file\n",
        "for idx in range(len(demo_before_finetune)):\n",
        "  print(f\"Example {idx + 1}:\")\n",
        "  print(demo_before_finetune[idx])\n",
        "  print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stf_U-9FqPjZ"
      },
      "source": [
        "## 微調整のためのハイパーパラメーターの設定\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2ilhBGhTDtU"
      },
      "outputs": [],
      "source": [
        "\"\"\" このハイパーパラメータで遊んでみることを強くお勧めする。 \"\"\"\n",
        "\n",
        "num_train_data = 1040 # ほとんどの場合, 可能な限り多くのデータを訓練したいでしょう. これにより, モデルがより多様な節を見ることができるようになり, 出力の質が向上しますが, 訓練時間も長くなります.\n",
        "                      # デフォルトのパラメータ(1040)を使用した場合: 微調整に約25分、全セルのフル稼働に約50分かかる。\n",
        "                      # 最大値(5000)を使用した場合: 微調整には約100分かかり, 全セルのフル実行には約120分かかる.\n",
        "\n",
        "\"\"\" これらのハイパーパラメータのいくつかを変更したいかもしれない（必ずしも必要ではない）。 \"\"\"\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive\"  # 結果を出力するディレクトリを設定する（別のディレクトリに結果を保存したい場合は、ここで変更できますが、デフォルトのサブディレクトリ、つまりGoogleドライブに保存することを強くお勧めします）\n",
        "ckpt_dir = \"./exp1\" # モデルのチェックポイントを保存するディレクトリを設定します（モデルのチェックポイントを別のディレクトリに保存したい場合は、ここで変更できます）。\n",
        "num_epoch = 1 # 学習する総エポック数を設定する（数値が大きいほど学習時間が長くなる。colabの無料版を利用する場合、学習時間が長すぎると切断される可能性があるので注意が必要）。\n",
        "LEARNING_RATE = 3e-4 # 学習率を設定する。\n",
        "\n",
        "\n",
        "\"\"\" このパラメータ設定コードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "cache_dir = \"./cache\" # キャッシュディレクトリのパスを設定します。\n",
        "from_ckpt = False # チェックポイントからモデルの重みをロードするかどうか, デフォルトはno.\n",
        "ckpt_name = None # 特定のチェックポイントから重みをロードする際に使用するファイル名、デフォルトはなし。\n",
        "dataset_dir = \"/content/drive/MyDrive/Tang_trainingdata_ja.json\" # データセットのディレクトリまたはファイルパスを設定します．\n",
        "logging_steps = 20 # 学習ログを出力するステップ数を定義します。\n",
        "save_steps = 65 # モデルを保存するステップ数を設定します。\n",
        "save_total_limit = 3 # モデルのチェックポイントを最大何回保持するかを制御します。\n",
        "report_to = None # 実験的メトリクスを報告する対象を設定します。\n",
        "MICRO_BATCH_SIZE = 4 # マイクロバッチのサイズを定義する\n",
        "BATCH_SIZE = 16 # バッチのサイズを定義する\n",
        "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE # 各マイクロバッチの累積グラデーションステップ数を計算する\n",
        "CUTOFF_LEN = 256 # テキストカットオフの最大長を設定します.\n",
        "LORA_R = 8 # LORA(Layer-wise Random Attention)のR値を設定します.\n",
        "LORA_ALPHA = 16 # LORAのアルファ値を設定します.\n",
        "LORA_DROPOUT = 0.05 # LORAのドロップアウト率を設定する。\n",
        "VAL_SET_SIZE = 0 # バリデーションセットのサイズを設定します。\n",
        "TARGET_MODULES = [\"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\", \"v_proj\"] # ターゲットとなるモジュールを設定する。\n",
        "device_map = \"auto\" # デバイスマップを設定。デフォルトは \"auto\"。\n",
        "world_size = int(os.environ.get(\"WORLD_SIZE\", 1)) # 環境変数 \"WORLD_SIZE \"の値を取得、設定されていない場合はデフォルトで1。\n",
        "ddp = world_size != 1 # world_sizeに基づいて分散データ処理(DDP)を使用するかどうかを判断。world_sizeが1の場合、DDPは使用されない。\n",
        "if ddp:\n",
        "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
        "    GRADIENT_ACCUMULATION_STEPS = GRADIENT_ACCUMULATION_STEPS // world_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REMmOD6L4tp9"
      },
      "source": [
        "## 微調整開始\n",
        "以下のコードブロックの実行時間は、デフォルト設定を使用した場合、約**10分**かかりますが、Colabの状態によって異なる場合があります。\n",
        "微調整の方法は、以下のサイトを参考：https://www.datacamp.com/tutorial/fine-tuning-qwen3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkOt2hDhR4lG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "c3e9c406737749a9aa3442821e727075",
            "16c66920794a449190eb07f1aa6def7e",
            "30306edf76d14fa0abf62ed47452efdb",
            "1e2d1c3a459c41c3b8ecb67597287214",
            "49841e80b3ef423c9810c9195d13ed12",
            "15d222347f6244a0b24d7c93014515f2",
            "7254e8cb09b94f59944033e44be13923",
            "c5986f8978b04916bd2b6b0fe6271835",
            "ed4adeda3d594faeb187a14e4d6306ed",
            "6559014e83c94bda8c6416487ed59c73",
            "f9201cd420f74aaea995b2f53d045158",
            "434ea35b5c594f5b84a8135a0efafe8b",
            "440312ca889f4f90b5b39bc6167bb233",
            "4e440e8a721e4276928865f6a7bdc243",
            "249afc06804341f9b855c5aee297e8c9",
            "1a78fbda6d49499cbcde83cad54a51c3",
            "cbbb95af248040ab89e3450f421e17cb",
            "aaf9f093eca046c7b34f0a6d373da785",
            "2c3579fcf47447b4afd75ea37ad90fce",
            "b342b77e1ead4d1ea243ff04520807c1",
            "295c135d31194ad681821b91ba9e77d2",
            "a43f8bea60f140e580d0f3a2f854368f"
          ]
        },
        "id": "6W-xe7h9ti0x",
        "outputId": "9ec3e0b6-cd08-410c-9ea7-8eca58071eb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3e9c406737749a9aa3442821e727075"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1040 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "434ea35b5c594f5b84a8135a0efafe8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 3.8121, 'grad_norm': 2.354698419570923, 'learning_rate': 0.00011399999999999999, 'epoch': 0.3076923076923077}\n",
            "{'loss': 2.3849, 'grad_norm': 0.9768972396850586, 'learning_rate': 0.000234, 'epoch': 0.6153846153846154}\n",
            "{'loss': 2.0298, 'grad_norm': 0.9623903632164001, 'learning_rate': 0.00011999999999999999, 'epoch': 0.9230769230769231}\n",
            "{'train_runtime': 206.5876, 'train_samples_per_second': 5.034, 'train_steps_per_second': 0.315, 'train_loss': 2.6803645647489107, 'epoch': 1.0}\n",
            "\n",
            " 上記のキーが見つからないという警告は無視してください :)\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "# create the output directory you specify\n",
        "os.makedirs(output_dir, exist_ok = True)\n",
        "os.makedirs(ckpt_dir, exist_ok = True)\n",
        "\n",
        "# 根據 from_ckpt 標誌，從 checkpoint 載入模型權重\n",
        "if from_ckpt:\n",
        "    model = PeftModel.from_pretrained(model, ckpt_name)\n",
        "\n",
        "# 將模型準備好以使用 INT8 訓練\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# 使用 LoraConfig 配置 LORA 模型\n",
        "config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=TARGET_MODULES,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "\n",
        "# トークナイザー 的 パディング トークン を 0に設定する\n",
        "tokenizer.pad_token_id = 0\n",
        "\n",
        "# トレーニングデータのロードと処理\n",
        "with open(dataset_dir, \"r\", encoding = \"utf-8\") as f:\n",
        "    data_json = json.load(f)\n",
        "with open(\"tmp_dataset.json\", \"w\", encoding = \"utf-8\") as f:\n",
        "    json.dump(data_json[:num_train_data], f, indent = 2, ensure_ascii = False)\n",
        "\n",
        "data = load_dataset('json', data_files=\"tmp_dataset.json\", download_mode=\"force_redownload\")\n",
        "\n",
        "# 学習データを学習セットと検証セットに分割する（VAL_SET_SIZEが0より大きい場合）\n",
        "if VAL_SET_SIZE > 0:\n",
        "    train_val = data[\"train\"].train_test_split(\n",
        "        test_size=VAL_SET_SIZE, shuffle=True, seed=42\n",
        "    )\n",
        "    train_data = train_val[\"train\"].shuffle().map(generate_training_data)\n",
        "    val_data = train_val[\"test\"].shuffle().map(generate_training_data)\n",
        "else:\n",
        "    train_data = data['train'].shuffle().map(generate_training_data)\n",
        "    val_data = None\n",
        "\n",
        "# トランスフォーマー・トレーナーによるモデル・トレーニング\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "        warmup_steps=50,\n",
        "        num_train_epochs=num_epoch,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        fp16=True,  # 混合精度トレーニングの使用\n",
        "        logging_steps=logging_steps,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=save_steps,\n",
        "        output_dir=ckpt_dir,\n",
        "        save_total_limit=save_total_limit,\n",
        "        ddp_find_unused_parameters=False if ddp else None,  # DDPを使用して勾配更新戦略を制御するかどうか\n",
        "        report_to=report_to,\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "# モデルのキャッシュ機能を無効にする\n",
        "model.config.use_cache = False\n",
        "\n",
        "# PyTorchバージョン2.0以降とWindows以外のシステムを使用している場合のモデルのコンパイル\n",
        "if torch.__version__ >= \"2\" and sys.platform != 'win32':\n",
        "    model = torch.compile(model)\n",
        "\n",
        "# モデルトレーニングの開始\n",
        "trainer.train()\n",
        "\n",
        "# 学習済みモデルを指定したディレクトリに保存する。\n",
        "model.save_pretrained(ckpt_dir)\n",
        "\n",
        "# トレーニング中にウェイトが不足する可能性があるという警告メッセージを表示する。\n",
        "print(\"\\n 上記のキーが見つからないという警告は無視してください :)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKeGb8bRqWux"
      },
      "source": [
        "##  テスト\n",
        "微調整は終わった。調整後のモデルをテストしたい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8I3stApnTWb"
      },
      "source": [
        "まず、保存した微調整済みモデル（チェックポイント）をロードする必要がある。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ag6GvOCe9Ql",
        "outputId": "26f474bc-0694-42ea-adae-b075c72c507e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all available checkpoints:\n",
            " id: checkpoint name\n",
            "  0: checkpoint-65\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "# find all available checkpoints\n",
        "ckpts = []\n",
        "for ckpt in os.listdir(ckpt_dir):\n",
        "    if (ckpt.startswith(\"checkpoint-\")):\n",
        "        ckpts.append(ckpt)\n",
        "\n",
        "# list all the checkpoints\n",
        "ckpts = sorted(ckpts, key = lambda ckpt: int(ckpt.split(\"-\")[-1]))\n",
        "print(\"all available checkpoints:\")\n",
        "print(\" id: checkpoint name\")\n",
        "for (i, ckpt) in enumerate(ckpts):\n",
        "    print(f\"{i:>3}: {ckpt}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khq-LbNlcdfp"
      },
      "outputs": [],
      "source": [
        "\"\"\" チェックポイントを変更したいと思うかもしれないが、必ずしも必要ではない。\"\"\"\n",
        "\n",
        "id_of_ckpt_to_use = -1 # 推論に使用するチェックポイントのID（前のセルの出力に対応）。\n",
        "                        # デフォルト値の-1は, 上記のチェックポイントのリストの中で \"最後から2番目 \"のチェックポイントを指します.\n",
        "                        # 他のチェックポイントを選択したい場合は, -1をリストにあるチェックポイントIDのどれかに変更します.\n",
        "\n",
        "ckpt_name = os.path.join(ckpt_dir, ckpts[id_of_ckpt_to_use])\n",
        "\n",
        "\"\"\" デコード・パラメータを変更する必要があるかもしれないが、必ずしも必要ではない。 \"\"\"\n",
        "\n",
        "# ここでデコードパラメータを調整することができます。デコードパラメータの詳細な説明については、宿題のスライドを参照してください。\n",
        "max_len = 256 # 生成される返信の最大長。\n",
        "temperature = 0.1 # 生成される返信のランダム性を設定。値が小さいほど返信が安定する。\n",
        "top_p = 0.3 # top-p(核)サンプリングのしきい値.\n",
        "# top_k = 5 # top-kの値を調整することで、生成される返答の多様性を高め、繰り返し単語が 生成されないようにする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTr0DfVBSekD"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルト設定を使用した場合、約2分**かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wKVPpMVtkql"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "test_data_path = \"/content/drive/MyDrive/Tang_testingdata_ja.json\"\n",
        "output_path = os.path.join(output_dir, \"results.txt\")\n",
        "\n",
        "cache_dir = \"./cache\" # キャッシュディレクトリのパスを設定する.\n",
        "seed = 42 # 結果を再現するためのランダムシードを設定する。\n",
        "no_repeat_ngram_size = 3 # 重複セグメントを生成しないように、no-repeat ngramのサイズを設定する。\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# トークン化器を使用して、モデル名をモデルが読み取り可能な数値表現に変換します。\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    cache_dir=cache_dir,\n",
        "    quantization_config=nf4_config\n",
        ")\n",
        "\n",
        "# 事前学習モデルからモデルをロードし、8ビット整数(INT8)モデルとして設定する。\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=nf4_config,\n",
        "    device_map={'': 0},  # 設定使用的設備，此處指定為 GPU 0\n",
        "    cache_dir=cache_dir\n",
        ")\n",
        "\n",
        "# 指定したチェックポイントからモデルの重みをロードする\n",
        "model = PeftModel.from_pretrained(model, ckpt_name, device_map={'': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs4_EtnoWA5b"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルト設定を使用した場合、約 **4**分かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcHoU2X8xRkn",
        "outputId": "9174c877-ea2d-4a5d-e173-3e566f08d7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 雪がきれいになり、銀の化粧は平凡で、オレンジはヒスイの枝を反映しています。 ★★★ 雲は太陽の上にあり、雲は太阳の上を覆っています。私は太陽を信じ、太陽は太陰を信じています。私は山の上で、私は山に登り、私は太陰に登ります。 あなたが山に来ると、あなたが太陽に来ます。. あなたは太極の上にあるので、あなたは山に到達します。. 電気の音は太空にあり，太陽が太空を覆っている。 私は太空中の雲を信じており、太空中に到着しました。私は太空中で、太空の雲に到来しました。</p> そして、私は雲に登るためには、私はまだ太陽を見ています。s> これは太陽と太陽です。y 水は太晴の空にあります。m> 月は太明の空で、月は月の空です。</p>y> あなたの名前は太気の空の上です。</s>y> 道は太氣の上\n",
            "2. マスターは何をしましたか？世代に住んでいます。 ★★★ あなたは何千もの人々を送り出しましたか、そしてあなたは誰ですか？私はあなたに言葉を送ります。 あなたが何千人もの人々に送り出すことは、あなたが誰ですか、そしてあなたの名前は誰ですか？ 雲は夜に降り、月は夜の月に降ります。</u> そして、あなたはあなた自身を送ってください、そして、あなたの名はあなたが送ります。あなたがあなた自身に送りますか？あなたがあなたの名を送しますか？あなたの名は何千もの人に送ります？</u>あなたが、あなた自身の名を贈りますか、あなたは何千人に送します。</u> 私はあなたに送るためには、あなたに何千人の人々を贈る必要がありますか？私はあなたの名と名を忘れて、あなたを送る必要があります。. あなたは何万もの人々を受け入れ、何千人に渡りますか。. 花は夜明けに咲いており、花は夜中に咲きます。</u> 秋の花は、春の花と違い、秋の花\n",
            "3. ラン・ルオはファングクイの庭に飛んで、クシフに旅行します。 ★★★ 雲は太陽の影を覆い、風は太阳の影に覆い。私は太陽を信じ、太陽は太陰を信じています。私は山の上に登り、山の下に登ります。 あなたが山に登るとき、あなたが太陽に登れるとき、あなたの心は太極にあります。. あなたは太気の山に来ました、そしてあなたは山の上でいました。. 電子は太氣の山を駆り出しました、そして太陽が太気を駁け出しました。 花は太気に覆われ、太気は太气を覆われます。太陽と太陽があります。[s] 道は太長であり、道は太短です。s> 遗憾は太重であり、太重は太輕です。</p> そして、太長は太光です。</h2> これは太陽です。</div> また、太光は太明です。</span> あなたの心が太光に覆われていると感じます。</p></\n",
            "4. 風が開き、フェスティバルが開き、灰色のリズムが最初のヤンを動かします。 ★★★ 雲は太陽の上にあり、雲は太阳の上を覆っています。私は太陽を知り、太陽は太陰を知っています。太陽が太陽に覆われ、太陰が太陰に覆われる。私はまだ太陽と太陰の上を見ています。 あなたが太極を知っていると、あなたがあなた自身を知ることはありません。. あなたは太極の上にあると信じています。</u> そして、あなたはあなた自身の心を知ることができます。</u>. そしてあなたはあなたの心を守ることができます。. 電気の光は太空にあり，太陽には太陽があります。 花は太空中にありと、太空は太晴です。太陽は何千もの光を提供しますか？。s> 道は太光に覆い、道は太明に覆っています。y> 青い雲は青い雲に覆っており、青い云は青く見えます。m> 高い雲が高くて、太晴の雲が太\n",
            "5. 昨夜、星は昨夜風が強く、絵画の建物の西側はギタンの東にありました。 ★★★ 雲は夜に降り、月は夜明けに降ります。私は夜に夜明けて、私は夜明ける夜に来ます。私は山の上に来ますが、私は山に来ません。 あなたが山に到達するのを待つことは、あなたがあなたに来ることを待っていることを示しています。. あなたはあなたに到着するのを見たことない。. 電子は夜の夜明かりにあり、私は彼の心を知っています。 私は彼のことを知っていますが、彼は彼を知っている。私は彼を愛しています。</p> そして、私はあなたに愛しています。私はあなたを愛していることを知っているので、私はあなたの心を愛します。s> あなたの心はあなたを知り、あなたはあなたの心に愛します。あなたは私の心を好きになることを知りませんか？ あなたが私の心にいることを知るには、あなたに心を抱いてください。y. 雨は夜中に降りており、私は雨に到ります。</\n",
            "6. 3日後、私はキッチンに行き、手を洗ってスープを作りました。 ★★★ 雲は夜に降り、風は夜の空に降ります。私は夜に夜に、私は夜を送り、私は彼の心を送ります。彼は彼の家に来ますが、彼は私の家にいます。 あなたが彼の家の庭に来ると、あなたが私の家を訪れます。. あなたは彼を訪問し、あなたはあなた自身を訪れるでしょう。. 電動の音は、音楽の音楽を鳴らし、音は音楽に鳴り、音が鳴ります。 私は彼に言います、私はあなたに言いますが、私はあなたの心を離れて、あなたに心を返します。私はあなたを訪れて、私は私の心を訪れた。[s] あなたに来ることを望み、あなたを送る。s> あなたの心は、あなたとあなたが心を抱いています。</p> そして、あなたは何千もの人々に会い、あなたには何千もの人が来ています。p> これは、あなたにとって、あなた自身にとって、あなたの心\n",
            "7. songyun、qinの木は長い間分離されており、2本のcarは本を書くために長い間旅行してきました。 ★★★ 雲は太陽の影を引き離しており、風は太阳の影に流れており、雲は太陰の影の上にあります。私は太陽を信じて、太陽は太極の上を通り過ぎるのです。 あなたが太陽に近づくために、あなたが遠くに近いことを知っていますか？ 電車は太空にあり、太空は太空中にあり。私はあなたに言葉を送り、あなたに道を送ります。. あなたは太気の気質を知っていますのか？</u> あなたの心は太氣の気味に満ちており、あなたはあなた自身を知っている。</u> 道は太气の気候に溝戻り、道は太気に戻ります。</u>. あなたの道は道にあります。</u> 水は太晴の気分で、太晴は太明の気配です。</u> 極の気は太清の気です。</u><u>太陽が太明に輝いており、太明は太光に\n",
            "8. 私は世界を助けて安心しますが、私は名声を招きません。 ★★★ 私は彼の心を知っていますが、彼は彼自身を知っていることを知っています。 あなたが彼のことを知っていること、あなたがあなた自身を愛していること、そしてあなたがあなたの心を愛しています。. あなたはあなた自身の心に心配していますか？. 私があなたを愛するのを知っていたら、私はあなたを恨んでいました。. 私の心は、あなたに心を配っていません。あなたが心配していることを知っていたこと、あなたの心はあなたに配られています。私はあなたに愛していますが、あなたは私の心を恨っています。</p> あなたの心が心に配られ、あなた自身が心を抱いています。/s>あなたの心に愛していることを忘れて、あなたを心配してください。/私の心はあなたの心と結びついており、私はあなたの心のことを心配します。? あなたは何をしていますか。, あなたに何をしています。</p><p>あなたはあなたのことを知り、あなたは何が心に入っているか。</p><\n",
            "9. 戒厳令なしで南に旅行する場合、誰が第9レベルでアドバイスの手紙を報告しますか？ ★★★ 道徳的な価値は、道徳的価倷は、価倶は、それらの価倉は、その価倆は、それは、それほど、それほこりは、それが、それなりに、それまでは、それの価格は、それを、それには、それと、それに、それはそれなりです。 あなたは、あなたが、あなたはあなたがあなたがあなたの心を守るための方法を知っていますか？ 運動は、運転は、あなたの心は、心は運軥です。</u> あなたの心が、あなたの魂を守ることを心配する。</u>. あなたが心を保つために、あなたを守ることは、あなた自身の心を保護することです。</p> そして、あなたに心を送ることは、あなたの人生を送ることです。</h> これは、あなたにとって、あなたと、あなたたちの心は心を抱いています。. あなたの魂は、魂を抱くことができます。</u> 高い価倿は、高価倧価倊です。</w> それ\n",
            "10. 類人猿と鳥はジアンシュを恐れることをためらい、風と雲は常に保護者です。 ★★★ 雲は太陽の影を覆い、風は太阳の影に覆われています。私は太陽を守り、太陽は太陰を守ります。私は山の上に住んでおり、私は山に住んでいると感じています。 あなたが山に来ると、あなたが来るとあなたが来るでしょう。. あなたは山に到達し、あなたはあなたが到達します。. 電子は太極を守っています、そして太極は太极を守っている。 私は太気を守っており、太気は太氣を守る。私は太気の上を守ることを心配しています。[s] 高い山は太气を守るために、太氣は太気が守られます。s> 高さは太高です、太高は太高いです。y 水は太低です、水は太低いです。</p> これは太陽と太陽に似ています。</p><p>太陽が太陽になることは、太陰が太陰になることはありません。</\n",
            "11. あなたは返品日がないかどうか尋ねました、そして、バシャンの夜の雨は秋の池に上がりました。 ★★★ 雲は夜に降り、月は夜の月に降ります。私は夜に夜に、私は夜の夜に来ます。私は、私は、私の心を壊して、私は私の心に落ちます。 あなたが、あなたがあなたを愛していることを知っていますか？あなたがあなたの心を愛していますか？ 電車は夜明けに降る、そして夜明ける夜明るい夜明かりは夜の中で降りています。. あなたはあなたが何を知っているか、あなたは何を学んでいるか、そしてあなたがどうしてあなたが幸せになるかを知っています。. 私は、私はあなたに愛しています、そして私はあなたを爱しています。 水は夜中に降りており、月が夜中に昇り、夜は夜の中です。あなたが夜に帰れ、あなたに来ることを望みます。</p> そして、あなたは何を望んでいるのですか？私はあなたが心配していることを望みますが、私はあなたの心に心配しています。</p><p>あなたは、あなたを心\n",
            "12. 私たちが出会ったときに別れを告げることは困難であり、東風が弱く、花は長引いています。 ★★★ 雲は遠くにあり、風は遠いです。私は山の上にいて、私は山にいるので、私は遠くから来ます。私は遠いから、私は西に来ます。 あなたが遠くにあることを知り、あなたが西にいることを知るためには、あなたは遠くて、あなたは何が悪いですか？ 電車は遠距離で、私はあなたに来ています。. あなたはあなたが来なかったとき、あなたに会いに行きました。. 私はあなたに何千もの言葉を述べました。 花は遠くなり、花が遠くなりますが、私は花を信じています。</u> そして、私はあなたの心を信じます。</u>. そして私はあなたを信じ、あなたを愛しています。</u>. 私があなたを知りたいと願っています。あなたがあなたがいないとき、私は何千の言葉であなたを説明します。, あなたに言葉はありますか？</u> 秋の風は強く、私は風を吹いています。: あなた\n",
            "13. 雲母スクリーンはろうそくの影の奥深くにあり、長い川が徐々に落ち、朝の星は沈みます。 ★★★ 雲は太陽の影を覆い、雲は太阳の影に覆われています。私は太陽を覆うために、私は太阳を覆すために、太陽は太陰を覆します。 あなたが太陽に触れたとき、あなたがあなた自身に触れて、あなたはあなた自身を触れてください。. あなたは太極の道を踏み、あなたは何千回も、あなたに触れるために、あなたを触れる必要があります。. 電気の光は太空にあり，太陽が太空を覆っています。 私は太空中の光を知っています。</p> 秋の風は太晴の風に覆い，太晴は太風に隠されています。私は太晴を覆って、太晴に隣接します。</p><p>私はあなたに言葉を送ります。> あなたに送ります。あなたはあなたの言葉に言います。>> あなたは何が悪いですか？。: あなたを送り、あなたを受けます。::: �\n",
            "14. ハイシェルフのゲストは実際にそこに行き、小さな庭の花が飛んでいました。 ★★★ 雲は太陽の影を引き離して、風は太阳の影に流れており、風が太陽に吹き飛ばされます。私は太陽を離れて、太陽が太阳を離れたように、太阳が太陰を離してきました。私はまだ太陽と太陽を見ていますが、太陰は太陰と太陰を見ています。 あなたが太極を信じていると、あなたがあなた自身を信じています。</w> そして、あなたはあなた自身の心を信じて、あなた自身が心を守る。. あなたは太極の心に心配していますか？</w> 電気の心は太気の気質を示しています。.</w> 太陽は太氣の気候を示し、太気は太气の気味を示します。</w> 気味は太気に近づくことができます。<w>太陽は、太極に近づいており、太氣は太极に近付いています。</w>. そして太陽は何千もの太陽ですか？。/w>。</w\n",
            "15. ヤチの美しい母親は窓に開いており、黄色い竹の歌は動いていて喪に服しています。 ★★★ 雲は太陽の上にあり、雲は太阳の上を覆っています。私は太陽を信じて、太陽は太陰を信じています。私は山の上で、私は山に来ます。 あなたが山に到達するのを待つことは、あなたが太陽に到着するのと同じです。. あなたは太極の上にあることを知っていますか？. 電気の音は太気の上であり、太気は太氣の上です。</u> そして、太氣は太气の上になります。</u>. そして太気が太気を覆うのを知っています。</u> 難しいな、太極は太极の上ですか？</u> 静かな太気と太気。</u><u>太気</u>. 非常な太気です。</p> これは太気に含まれています。</p>. 花は太気に含まれています、そして太陽が太気に覆われています。</u> 芹菜は太気が含まれています。太陽と太陽があります。<u></\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "results = []\n",
        "\n",
        "# ランダム性、ビームサーチ、その他の関連パラメータを含む生成コンフィギュレーションを設定する。\n",
        "generation_config = GenerationConfig(\n",
        "    do_sample=True,\n",
        "    temperature=temperature,\n",
        "    num_beams=1,\n",
        "    top_p=top_p,\n",
        "    # top_k=top_k,\n",
        "    no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "    pad_token_id=2\n",
        ")\n",
        "\n",
        "# テストデータの読み込み\n",
        "with open(test_data_path, \"r\", encoding = \"utf-8\") as f:\n",
        "    test_datas = json.load(f)\n",
        "\n",
        "# 各テストデータに対して予測を行い、結果を保存する。\n",
        "with open(output_path, \"w\", encoding = \"utf-8\") as f:\n",
        "  for (i, test_data) in enumerate(test_datas):\n",
        "      predict = evaluate(test_data[\"instruction\"], generation_config, max_len, test_data[\"input\"], verbose = False)\n",
        "      f.write(f\"{i+1}. {test_data['input']} ★★★ {predict}\\n\")\n",
        "      print(f\"{i+1}. {test_data['input']} ★★★ {predict}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tJT1WINKXV7"
      },
      "source": [
        "## **重要なこと**： 15個の唐詩の結果を提出 .\n",
        "これらの唐詩の結果は \"/drive/content/MyDrive/results.txt \"にあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT78LeWaJM4D"
      },
      "source": [
        "## ファインチューニング・モデルとファインチューニングなしのモデルの比較をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx_mZZAZWdiE"
      },
      "source": [
        "ここで、上の「微調整前の推論」で見たのと同じ例で、我々のモデルがどのようなことができるかをチェックする。\n",
        "\n",
        "以下のコードブロックの実行時間は、デフォルトの設定であれば**40**秒程度ですが、Colabの状態によって異なるかもしれません。ここで、上の「微調整前の推論」で見たのと同じ例で、我々のモデルがどのようなことができるかをチェックする。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtDG2WhIWZlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0036477-15e9-403c-a91b-5cb97815c33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。日本語以外に出力しない。\n",
            "\n",
            "会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。\n",
            "\n",
            "モデル出力:\n",
            "雲は太陽の上にあり、風は太阳の上を吹いており、風が太陽を吹くと、太陽が太阳を吹き飛ばされます。 あなたは太陰を吹いているので、あなたはあなた自身を吹きます。. あなたが太陰に近づくことは、あなたがあなた自身に近付くことはありません。. 電気の力は太極の力と同様に、太極は太気の力を保持します。 花は太氣の力に近いので、太気は太气の力の力です。太陽は太元の上にあるので、私は太陽に近付けたいです。</p> そして、太元は太一の上です。</w> これは太陽と太元を結ぶものです。[ 水は太半の水と太半にあります。, そして太陽は何千もの太陽です。</g> あなたの心は太阴阳性にあります。あなたが心を閉じた場合、あなた自身は太阴の心\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。日本語以外に出力しない。\n",
            "\n",
            "重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。\n",
            "\n",
            "モデル出力:\n",
            "雲は夜に降り、月は夜の月に降る。私は夜に夜に、私は夜を送り、私は月を送ります。 あなたが夜に来ると、あなたが来るとあなたが来る。. あなたはあなたが、あなたはあなたの心を守る。. 電車は夜明けに降ります。</u> そして、私はあなたに言葉を送る。</u>. そして私はあなたを送ることを望みます。</u>.. 難しいことは、あなたに何千もの言葉があります。 認識は、あなたを知っています。あなたがあなたを守ることを心配する。, あなたに心配を送ることはできません。: あなたを心に配慮する。</u>. 課税は、あなたの心に含まれています。: 水は夜、月が夜、そして、月の月は月。:: 美しい景色は、月に含まれます。; そしてあなたは、夜にあなたがいる。>::\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。日本語以外に出力しない。\n",
            "\n",
            "逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。\n",
            "\n",
            "モデル出力:\n",
            "雲は太陽の上にあり、雲は太阳の上にある。 雪は太陰の上を覆い、雲が太陽を覆う。 道は太極の上であり、道は太极の上である。 あなたが道を歩くと、あなたが太極を歩いていると感じます。. あなたは太気を知り、あなたは道を知っています。. 電気の音は太氣の音と相似であり、太気の声は太气の音に相似です。 水は太気に流れており、水は太気が流れていて、水が太気に流れてきます。太陽は太光に流れるのを知っている。> 雨は太明に流れ、太明は太清に流れます。[ 私は太の上を見ています。太陽が太の上で流れて、太陽と太陽があります。/s> 太陽は夜に流されており、太陰は夜の夜に流れます。</p> そして\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# test demo examples\n",
        "test_tang_list = ['会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。',\n",
        "                  '重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。',\n",
        "                  '逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。']\n",
        "\n",
        "# get the model output for each examples\n",
        "demo_before_finetune = []\n",
        "for tang in test_tang_list:\n",
        "  demo_before_finetune.append(f'モデル入力:\\n{system_prompt}\\n\\n{tang}\\n\\nモデル出力:\\n'+evaluate(system_prompt, generation_config, max_len, tang, verbose = False))\n",
        "\n",
        "# print and store the output to text file\n",
        "for idx in range(len(demo_before_finetune)):\n",
        "  print(f\"Example {idx + 1}:\")\n",
        "  print(demo_before_finetune[idx])\n",
        "  print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wagFeDX4Hpa8"
      },
      "source": [
        "## **重要**： 上記の3つの例は提出しないでください。\n",
        "この3つの例は、微調整前と微調整後のモデルのパフォーマンスを比較するためだけに使用されます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWgTS13bgnWQ"
      },
      "source": [
        "## 結果のダウンロード\n",
        "宿題を終わらせるには、このファイルが必要です。 ブラウザが自動的にダウンロードしない場合は、Google Driveにあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUDuNQOY4os_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "eb00e465-95c3-433d-f7d9-01c4ab9f3041"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9d30b453-a18f-46b2-b363-ef1403837bb0\", \"results.txt\", 16426)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(output_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3e9c406737749a9aa3442821e727075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16c66920794a449190eb07f1aa6def7e",
              "IPY_MODEL_30306edf76d14fa0abf62ed47452efdb",
              "IPY_MODEL_1e2d1c3a459c41c3b8ecb67597287214"
            ],
            "layout": "IPY_MODEL_49841e80b3ef423c9810c9195d13ed12"
          }
        },
        "16c66920794a449190eb07f1aa6def7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15d222347f6244a0b24d7c93014515f2",
            "placeholder": "​",
            "style": "IPY_MODEL_7254e8cb09b94f59944033e44be13923",
            "value": "Generating train split: "
          }
        },
        "30306edf76d14fa0abf62ed47452efdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5986f8978b04916bd2b6b0fe6271835",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed4adeda3d594faeb187a14e4d6306ed",
            "value": 1
          }
        },
        "1e2d1c3a459c41c3b8ecb67597287214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6559014e83c94bda8c6416487ed59c73",
            "placeholder": "​",
            "style": "IPY_MODEL_f9201cd420f74aaea995b2f53d045158",
            "value": " 1040/0 [00:00&lt;00:00, 26551.08 examples/s]"
          }
        },
        "49841e80b3ef423c9810c9195d13ed12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d222347f6244a0b24d7c93014515f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7254e8cb09b94f59944033e44be13923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5986f8978b04916bd2b6b0fe6271835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ed4adeda3d594faeb187a14e4d6306ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6559014e83c94bda8c6416487ed59c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9201cd420f74aaea995b2f53d045158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "434ea35b5c594f5b84a8135a0efafe8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_440312ca889f4f90b5b39bc6167bb233",
              "IPY_MODEL_4e440e8a721e4276928865f6a7bdc243",
              "IPY_MODEL_249afc06804341f9b855c5aee297e8c9"
            ],
            "layout": "IPY_MODEL_1a78fbda6d49499cbcde83cad54a51c3"
          }
        },
        "440312ca889f4f90b5b39bc6167bb233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbbb95af248040ab89e3450f421e17cb",
            "placeholder": "​",
            "style": "IPY_MODEL_aaf9f093eca046c7b34f0a6d373da785",
            "value": "Map: 100%"
          }
        },
        "4e440e8a721e4276928865f6a7bdc243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3579fcf47447b4afd75ea37ad90fce",
            "max": 1040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b342b77e1ead4d1ea243ff04520807c1",
            "value": 1040
          }
        },
        "249afc06804341f9b855c5aee297e8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295c135d31194ad681821b91ba9e77d2",
            "placeholder": "​",
            "style": "IPY_MODEL_a43f8bea60f140e580d0f3a2f854368f",
            "value": " 1040/1040 [00:01&lt;00:00, 841.06 examples/s]"
          }
        },
        "1a78fbda6d49499cbcde83cad54a51c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbbb95af248040ab89e3450f421e17cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf9f093eca046c7b34f0a6d373da785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c3579fcf47447b4afd75ea37ad90fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b342b77e1ead4d1ea243ff04520807c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "295c135d31194ad681821b91ba9e77d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43f8bea60f140e580d0f3a2f854368f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}