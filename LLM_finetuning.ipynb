{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sit-xinli/ai-course5/blob/main/LLM_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh5rwbr4q5Nw"
      },
      "source": [
        "## 大規模言語モデルのファインチューニング\n",
        "LLMが唐詩を書けるように、あなたのLLMを微調整します。.\n",
        "\n",
        "**TODOs**\n",
        "1. スライドを読み、この宿題の目的を確認してください。\n",
        "2. このColabノートをコピーして保存してください。\n",
        "3. このColabノートの手順に従って、LLMを微調整する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRKf5DA69b3r"
      },
      "source": [
        "## GPUをアクティブにする\n",
        "\n",
        "モデルを微調整するので、この宿題が妥当な時間（1～2時間）でできるように、GPUをアクティブにする必要があります。\n",
        "\n",
        "T4 GPUを使っていることを確認！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8cXGoOcCLrK"
      },
      "source": [
        "\n",
        "## 事前データ準備\n",
        "Tang_testingdata_ja.jsonとTang_trainingdata_ja.jsonをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4irqfznNAlrZ",
        "outputId": "25031419-76f0-4f09-d135-37a2c26e200a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'dataset' already exists and is not an empty directory.\n",
            "cache  dataset\texp1  sample_data  tmp_dataset.json\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "#if not os.path.exists('dataset/'):\n",
        "!git clone https://github.com/sit-xinli/dataset.git\n",
        "!ls /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hJFrdFQn84M"
      },
      "source": [
        "## パッケージのインストール\n",
        "私たちは、微調整を容易にするために、他の人が作成したよくできたパッケージをインストールし、インポートします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UoAVpcAELzB"
      },
      "source": [
        "以下のコードブロックの実行にかかる時間は約 **5**分ですが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kuRMjk0rtWBx",
        "outputId": "effe480a-b738-4c64-8ecb-dca1cf807c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.7.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "!pip install bitsandbytes\n",
        "!pip install transformers\n",
        "!pip install peft\n",
        "!pip install sentencepiece\n",
        "!pip install colorama\n",
        "!pip install fsspec==2025.3.0\n",
        "!pip install -U datasets\n",
        "!pip install -U accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OMmuIblEXiU"
      },
      "source": [
        "以下のコードブロックの実行時間は約**20**秒ですが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZVVG_SQrvFpe"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import json\n",
        "import warnings\n",
        "import logging\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import bitsandbytes as bnb\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import transformers, datasets\n",
        "from peft import PeftModel\n",
        "from colorama import *\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from transformers import GenerationConfig\n",
        "from peft import (\n",
        "    #prepare_model_for_int8_training,\n",
        "    prepare_model_for_kbit_training,\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    prepare_model_for_kbit_training\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCo1znQhpBdt"
      },
      "source": [
        "## 微調整用データセットのダウンロード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTaVpMgzp3oC"
      },
      "source": [
        "## 便利な関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import google.auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "creds, _ = google.auth.default()\n",
        "service = build('oauth2', 'v2', credentials=creds)\n",
        "user_info = service.userinfo().get().execute()\n",
        "email = user_info['email']\n",
        "print(\"Authenticated as:\", email)\n",
        "import hashlib\n",
        "\n",
        "# Hash the email and convert to a number\n",
        "hash_digest = hashlib.sha256(email.encode()).hexdigest()\n",
        "numeric_value = int(hash_digest, 16)\n",
        "\n",
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "seed = numeric_value % 101\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "Jy4BPnhU5myO",
        "outputId": "b6f2b68d-ed30-4491-8fb1-3e184b1c76b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated as: xinli@center.shonan-it.ac.jp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dKjoLO3xtfM1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# トレーニングデータの作成\n",
        "def generate_training_data(data_point):\n",
        "    \"\"\"\n",
        "    (1) 目的\n",
        "        - この関数は、データポイント（入力テキストと出力テキスト）を、モデルが読み取れるトークンに変換するために使用される。\n",
        "    (2) 引数\n",
        "        - data_point: dict。フィールドは \"instruction\"、\"input\"、\"output\"。\n",
        "    (3) 返り値\n",
        "        - モデルの入力トークン、モデルを因果的にするアテンションマスク、対応する出力ターゲットを持つdict\n",
        "    (3) 例：\n",
        "        - フィールド \"instruction\"、\"input\"、\"output \"がすべてstrであるdict、data_point_1を作成した場合、この関数は次のように使うことができる：\n",
        "            formulate_article(データ_point_1)\n",
        "    \"\"\"\n",
        "    # construct full input prompt\n",
        "    prompt = f\"\"\"\\\n",
        "[INST] <<SYS>>\n",
        "あなたは親切なアシスタントだし、唐詩を書くこともうまい。\n",
        "<</SYS>>\n",
        "\n",
        "{data_point[\"instruction\"]}\n",
        "{data_point[\"input\"]}\n",
        "[/INST]\"\"\"\n",
        "\n",
        "    # count the number of input tokens\n",
        "    len_user_prompt_tokens = (\n",
        "        len(\n",
        "            tokenizer(\n",
        "                prompt,\n",
        "                truncation=True,\n",
        "                max_length=CUTOFF_LEN + 1,\n",
        "                padding=\"max_length\",\n",
        "            )[\"input_ids\"]\n",
        "        ) - 1\n",
        "    )\n",
        "    # transform input prompt into tokens\n",
        "    full_tokens = tokenizer(\n",
        "        prompt + \" \" + data_point[\"output\"] + \"</s>\",\n",
        "        truncation=True,\n",
        "        max_length=CUTOFF_LEN + 1,\n",
        "        padding=\"max_length\",\n",
        "    )[\"input_ids\"][:-1]\n",
        "    return {\n",
        "        \"input_ids\": full_tokens,\n",
        "        \"labels\": [-100] * len_user_prompt_tokens\n",
        "        + full_tokens[len_user_prompt_tokens:],\n",
        "        \"attention_mask\": [1] * (len(full_tokens)),\n",
        "    }\n",
        "\n",
        "# 生成された回答の評価\n",
        "def evaluate(instruction, generation_config, max_len, input=\"\", verbose=True):\n",
        "    \"\"\"\n",
        "    (1) 目標\n",
        "        - この関数は、与えられた入力文字列からモデルの出力を得るために使われる。\n",
        "\n",
        "    (2) 引数：\n",
        "        - instruction: str, モデルに何をさせたいかの説明。\n",
        "        - generation_config: transformers.GenerationConfigオブジェクト、モデルの推論に関連するデコードパラメータを指定する。\n",
        "        - max_len: int, モデルの出力の最大長。\n",
        "        - input: str, モデルが命令を解くために必要な入力文字列、デフォルトは\"\"(入力なし)\n",
        "        - verbose: bool, モードの出力を表示するかどうか、デフォルトはTrue\n",
        "    (3) 戻り値\n",
        "        - output: str, 命令と入力に従ったモードの応答\n",
        "    (4) 例\n",
        "        - 命令が \"ABC\"、入力が \"DEF \"で、128トークン以下の回答をモデルに与えたい場合、この関数を次のように使うことができる：\n",
        "            evaluate(instruction=\"ABC\", generation_config=generation_config, max_len=128, input=\"DEF\")\n",
        "\n",
        "    \"\"\"\n",
        "    # construct full input prompt\n",
        "    prompt = f\"\"\"\\\n",
        "[INST] <<SYS>>\n",
        "あなたは親切なアシスタントだし、唐詩を書くこともうまい。\n",
        "<</SYS>>\n",
        "\n",
        "{instruction}\n",
        "{input}\n",
        "[/INST]\"\"\"\n",
        "    # プロンプトのテキストをモデルが必要とする数値表現に変換する。\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].cuda()\n",
        "    # モデルを使って返信を生成する\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=generation_config,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "        max_new_tokens=max_len,\n",
        "    )\n",
        "    # 生成された応答をデコードしてプリントアウトする。\n",
        "    for s in generation_output.sequences:\n",
        "        output = tokenizer.decode(s)\n",
        "        output = output.split(\"[/INST]\")[1].replace(\"</s>\", \"\").replace(\"<s>\", \"\").replace(\"Assistant:\", \"\").replace(\"Assistant\", \"\").strip()\n",
        "        if (verbose):\n",
        "            print(output)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNxuuclCqFf5"
      },
      "source": [
        "## 微調整前のモデルと推論をダウンロードする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmfEFM7TNuRC"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルトの設定を使用した場合、約 **10**分かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq6WXaBnxYq"
      },
      "source": [
        "## 微調整前の推論\n",
        "まず、ファインチューニングなしのモデルで何ができるかを見てみよう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox5QRpz4NiPg"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルトの設定を使用した場合、約2分**かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "e1sFQbHGn3Bw"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "model_name = \"Qwen/Qwen3-0.6B\" # 微調整に使用するモデルを設定する。\n",
        "cache_dir = \"./cache\"\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# 指定されたモデル名またはパスから，事前に学習された言語モデルを読み込みます．\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    cache_dir=cache_dir,\n",
        "    quantization_config=nf4_config,\n",
        "    low_cpu_mem_usage = True\n",
        ")\n",
        "\n",
        "# トークナイザーを作成し、終了シンボル(eos_token)を設定します。\n",
        "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    add_eos_token=True,\n",
        "    cache_dir=cache_dir,\n",
        "    #quantization_config=nf4_config\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# モデル推論のためのデコーディング・パラメータの設定\n",
        "max_len = 128\n",
        "generation_config = GenerationConfig(\n",
        "    do_sample=True,\n",
        "    temperature=0.1,\n",
        "    num_beams=1,\n",
        "    top_p=0.3,\n",
        "    no_repeat_ngram_size=3,\n",
        "    pad_token_id=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LyTYIcDOAkO"
      },
      "source": [
        "以下のコードブロックは、デフォルトの設定を使用した場合、実行に約 **1** 分かかりますが、Colab の状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QJyuoPoO2TCr",
        "outputId": "85b268cc-27e3-4a6f-9c38-9f4153e5f5d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。\n",
            "\n",
            "会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。\n",
            "\n",
            "モデル出力:\n",
            "この詩は、詩の内容をより簡潔にするために、詩を短くした。  \n",
            "詩の文脈を把握し、詩に含まれている名前や人物や物語を簡素に記述し、  \n",
            "詩に必要な情報を簡潔にして、  \n",
            "この唐詩は「東風の力が強いため、東風が花を散った」と簡潔な表現にまとめられます。\n",
            "\n",
            "この詩の名前、人物、物語、テーマ、内容、文脈、テーマの内容、テーマをまとめると、  \n",
            "**「東风の力」**  \n",
            "**\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。\n",
            "\n",
            "重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。\n",
            "\n",
            "モデル出力:\n",
            "この詩は、詩の名前は「重いのカーヤントの下に深い喪に着ていた」という詩です。\n",
            "\n",
            "この詩の内容を簡約にまとめると、  \n",
            "**「重くしたカーボンの上に深いた喪にいた、夜は長い」**  \n",
            "となります。\n",
            "\n",
            "この唐詩は「長く夜の深さ」を表しています。\n",
            "\n",
            "この诗の内容は、  \n",
            "「重いたカーリンの夜は深い」  \n",
            "と簡潔でまとめられています。\n",
            "\n",
            "詩の文脈を考慮して、  \n",
            "この唐诗の名\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。\n",
            "\n",
            "逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。\n",
            "\n",
            "モデル出力:\n",
            "この詩は、詩の名前と内容を記述して、簡潔で、一言でまとめ、一観をまとめ、まとめ、整理、整理して、整理し、整理した内容をまとめると、  \n",
            "**「**  \n",
            "**詩名：**  \n",
            "「**逃亡**の果たに追かえる香りにのる星，**禁断**の園に驚き**に溁ちている。**」  \n",
            "**内容：** 這詩は，詩の内容を簡素にまとめると，  \n",
            "****  \n",
            "詩の名称：逃亡  \n",
            "詩\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "# demo examples\n",
        "test_tang_list = ['会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。',\n",
        "                  '重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。',\n",
        "                  '逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。']\n",
        "\n",
        "system_prompt = '以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。'\n",
        "\n",
        "# get the model output for each examples\n",
        "demo_before_finetune = []\n",
        "for tang in test_tang_list:\n",
        "  demo_before_finetune.append(f'モデル入力:\\n{system_prompt}\\n\\n{tang}\\n\\nモデル出力:\\n'+evaluate(system_prompt, generation_config, max_len, tang, verbose = False))\n",
        "\n",
        "# print and store the output to text file\n",
        "for idx in range(len(demo_before_finetune)):\n",
        "  print(f\"Example {idx + 1}:\")\n",
        "  print(demo_before_finetune[idx])\n",
        "  print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stf_U-9FqPjZ"
      },
      "source": [
        "## 微調整のためのハイパーパラメーターの設定\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Q2ilhBGhTDtU"
      },
      "outputs": [],
      "source": [
        "\"\"\" このハイパーパラメータで遊んでみることを強くお勧めする。 \"\"\"\n",
        "\n",
        "num_train_data = 1040 # ほとんどの場合, 可能な限り多くのデータを訓練したいでしょう. これにより, モデルがより多様な節を見ることができるようになり, 出力の質が向上しますが, 訓練時間も長くなります.\n",
        "                      # デフォルトのパラメータ(1040)を使用した場合: 微調整に約25分、全セルのフル稼働に約50分かかる。\n",
        "                      # 最大値(5000)を使用した場合: 微調整には約100分かかり, 全セルのフル実行には約120分かかる.\n",
        "\n",
        "\"\"\" これらのハイパーパラメータのいくつかを変更したいかもしれない（必ずしも必要ではない）。 \"\"\"\n",
        "\n",
        "output_dir = \"/content/dataset\"  # 結果を出力するディレクトリを設定する（別のディレクトリに結果を保存したい場合は、ここで変更できますが、デフォルトのサブディレクトリ、つまりGoogleドライブに保存することを強くお勧めします）\n",
        "ckpt_dir = \"./exp1\" # モデルのチェックポイントを保存するディレクトリを設定します（モデルのチェックポイントを別のディレクトリに保存したい場合は、ここで変更できます）。\n",
        "num_epoch = 1 # 学習する総エポック数を設定する（数値が大きいほど学習時間が長くなる。colabの無料版を利用する場合、学習時間が長すぎると切断される可能性があるので注意が必要）。\n",
        "LEARNING_RATE = 3e-4 # 学習率を設定する。\n",
        "\n",
        "\n",
        "\"\"\" このパラメータ設定コードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "cache_dir = \"./cache\" # キャッシュディレクトリのパスを設定します。\n",
        "from_ckpt = False # チェックポイントからモデルの重みをロードするかどうか, デフォルトはno.\n",
        "ckpt_name = None # 特定のチェックポイントから重みをロードする際に使用するファイル名、デフォルトはなし。\n",
        "dataset_dir = \"/content/dataset/Tang_trainingdata_ja.json\" # データセットのディレクトリまたはファイルパスを設定します．\n",
        "logging_steps = 20 # 学習ログを出力するステップ数を定義します。\n",
        "save_steps = 65 # モデルを保存するステップ数を設定します。\n",
        "save_total_limit = 3 # モデルのチェックポイントを最大何回保持するかを制御します。\n",
        "report_to = None # 実験的メトリクスを報告する対象を設定します。\n",
        "MICRO_BATCH_SIZE = 4 # マイクロバッチのサイズを定義する\n",
        "BATCH_SIZE = 16 # バッチのサイズを定義する\n",
        "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE # 各マイクロバッチの累積グラデーションステップ数を計算する\n",
        "CUTOFF_LEN = 256 # テキストカットオフの最大長を設定します.\n",
        "LORA_R = 8 # LORA(Layer-wise Random Attention)のR値を設定します.\n",
        "LORA_ALPHA = 16 # LORAのアルファ値を設定します.\n",
        "LORA_DROPOUT = 0.05 # LORAのドロップアウト率を設定する。\n",
        "VAL_SET_SIZE = 0 # バリデーションセットのサイズを設定します。\n",
        "TARGET_MODULES = [\"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\", \"v_proj\"] # ターゲットとなるモジュールを設定する。\n",
        "device_map = \"auto\" # デバイスマップを設定。デフォルトは \"auto\"。\n",
        "world_size = int(os.environ.get(\"WORLD_SIZE\", 1)) # 環境変数 \"WORLD_SIZE \"の値を取得、設定されていない場合はデフォルトで1。\n",
        "ddp = world_size != 1 # world_sizeに基づいて分散データ処理(DDP)を使用するかどうかを判断。world_sizeが1の場合、DDPは使用されない。\n",
        "if ddp:\n",
        "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
        "    GRADIENT_ACCUMULATION_STEPS = GRADIENT_ACCUMULATION_STEPS // world_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REMmOD6L4tp9"
      },
      "source": [
        "## 微調整開始\n",
        "以下のコードブロックの実行時間は、デフォルト設定を使用した場合、約**10分**かかりますが、Colabの状態によって異なる場合があります。\n",
        "微調整の方法は、以下のサイトを参考：https://www.datacamp.com/tutorial/fine-tuning-qwen3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkOt2hDhR4lG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6W-xe7h9ti0x",
        "outputId": "81f5c9a6-416d-4496-fe5b-1efbb58e5439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "ec3751ef70574744a40e92066cf0bbd1",
            "78000f7ce8334836a9403c837d687389",
            "50f2b266aab54e27b291ba8dfaad9eef",
            "80af4447e8494264898c5d7b924f45fa",
            "8d3b8fe057f647839e7f24e0c16f3bcd",
            "12f263c062d344e69f9d8fc86d9b99bc",
            "d94a94cb45b94e7f86b2fe282f97ee6e",
            "4af14d45902a418297e5cc6597a70416",
            "4c96c10ab79f467b805031f9c7e7b606",
            "b2ced1e122fd498a83d914d88ab5d7c0",
            "61fbca90c2fe4b0f97dfffc928d8e6bd",
            "808987d651a94d9095e2cf493d2a6847",
            "df82c367019c4bfc922bd113b29e3540",
            "eb14bc21ef114edfad0e883e415c0cb8",
            "b8c8b1ae852942af8ef14b41dd57c728",
            "2acc8ad702fb497cbb403416f9f4ebe0",
            "0158f0ab5d754dcda0b87fc34d1c0145",
            "5f4bc408d3bb42c2b8f2941585aa2ad6",
            "e19afb0f424c41c3ada46f8953d355ab",
            "e286e3729d954ce99f626bbbd1815ff0",
            "e3688c2b88e04cd38382dd684a16381b",
            "e5f239e73ebf480db670779196d12d69"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec3751ef70574744a40e92066cf0bbd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1040 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "808987d651a94d9095e2cf493d2a6847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 3.9915, 'grad_norm': 1.7977006435394287, 'learning_rate': 0.00011399999999999999, 'epoch': 0.3076923076923077}\n",
            "{'loss': 2.5777, 'grad_norm': 1.0017991065979004, 'learning_rate': 0.000234, 'epoch': 0.6153846153846154}\n",
            "{'loss': 2.2541, 'grad_norm': 0.9578112363815308, 'learning_rate': 0.00011999999999999999, 'epoch': 0.9230769230769231}\n",
            "{'train_runtime': 197.7953, 'train_samples_per_second': 5.258, 'train_steps_per_second': 0.329, 'train_loss': 2.880238753098708, 'epoch': 1.0}\n",
            "\n",
            " 上記のキーが見つからないという警告は無視してください :)\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\" # disables online logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\" # disables wandb entirely\n",
        "\n",
        "# create the output directory you specify\n",
        "os.makedirs(output_dir, exist_ok = True)\n",
        "os.makedirs(ckpt_dir, exist_ok = True)\n",
        "\n",
        "# 根據 from_ckpt 標誌，從 checkpoint 載入模型權重\n",
        "if from_ckpt:\n",
        "    model = PeftModel.from_pretrained(model, ckpt_name)\n",
        "\n",
        "# 將模型準備好以使用 INT8 訓練\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# 使用 LoraConfig 配置 LORA 模型\n",
        "config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=TARGET_MODULES,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "\n",
        "# トークナイザー 的 パディング トークン を 0に設定する\n",
        "tokenizer.pad_token_id = 0\n",
        "\n",
        "# トレーニングデータのロードと処理\n",
        "with open(dataset_dir, \"r\", encoding = \"utf-8\") as f:\n",
        "    data_json = json.load(f)\n",
        "with open(\"tmp_dataset.json\", \"w\", encoding = \"utf-8\") as f:\n",
        "    json.dump(data_json[:num_train_data], f, indent = 2, ensure_ascii = False)\n",
        "\n",
        "data = load_dataset('json', data_files=\"tmp_dataset.json\", download_mode=\"force_redownload\")\n",
        "\n",
        "# 学習データを学習セットと検証セットに分割する（VAL_SET_SIZEが0より大きい場合）\n",
        "if VAL_SET_SIZE > 0:\n",
        "    train_val = data[\"train\"].train_test_split(\n",
        "        test_size=VAL_SET_SIZE, shuffle=True, seed=42\n",
        "    )\n",
        "    train_data = train_val[\"train\"].shuffle().map(generate_training_data)\n",
        "    val_data = train_val[\"test\"].shuffle().map(generate_training_data)\n",
        "else:\n",
        "    train_data = data['train'].shuffle().map(generate_training_data)\n",
        "    val_data = None\n",
        "\n",
        "# トランスフォーマー・トレーナーによるモデル・トレーニング\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "        warmup_steps=50,\n",
        "        num_train_epochs=num_epoch,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        fp16=True,  # 混合精度トレーニングの使用\n",
        "        logging_steps=logging_steps,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=save_steps,\n",
        "        output_dir=ckpt_dir,\n",
        "        save_total_limit=save_total_limit,\n",
        "        ddp_find_unused_parameters=False if ddp else None,  # DDPを使用して勾配更新戦略を制御するかどうか\n",
        "        report_to=report_to,\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "# モデルのキャッシュ機能を無効にする\n",
        "model.config.use_cache = False\n",
        "\n",
        "# PyTorchバージョン2.0以降とWindows以外のシステムを使用している場合のモデルのコンパイル\n",
        "if torch.__version__ >= \"2\" and sys.platform != 'win32':\n",
        "    model = torch.compile(model)\n",
        "\n",
        "# モデルトレーニングの開始\n",
        "trainer.train()\n",
        "\n",
        "# 学習済みモデルを指定したディレクトリに保存する。\n",
        "model.save_pretrained(ckpt_dir)\n",
        "\n",
        "# トレーニング中にウェイトが不足する可能性があるという警告メッセージを表示する。\n",
        "print(\"\\n 上記のキーが見つからないという警告は無視してください :)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKeGb8bRqWux"
      },
      "source": [
        "##  テスト\n",
        "微調整は終わった。調整後のモデルをテストしたい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8I3stApnTWb"
      },
      "source": [
        "まず、保存した微調整済みモデル（チェックポイント）をロードする必要がある。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5ag6GvOCe9Ql",
        "outputId": "adaeed40-8cc7-4eb6-a8b0-524d46cdb14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all available checkpoints:\n",
            " id: checkpoint name\n",
            "  0: checkpoint-65\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "# find all available checkpoints\n",
        "ckpts = []\n",
        "for ckpt in os.listdir(ckpt_dir):\n",
        "    if (ckpt.startswith(\"checkpoint-\")):\n",
        "        ckpts.append(ckpt)\n",
        "\n",
        "# list all the checkpoints\n",
        "ckpts = sorted(ckpts, key = lambda ckpt: int(ckpt.split(\"-\")[-1]))\n",
        "print(\"all available checkpoints:\")\n",
        "print(\" id: checkpoint name\")\n",
        "for (i, ckpt) in enumerate(ckpts):\n",
        "    print(f\"{i:>3}: {ckpt}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "khq-LbNlcdfp"
      },
      "outputs": [],
      "source": [
        "\"\"\" チェックポイントを変更したいと思うかもしれないが、必ずしも必要ではない。\"\"\"\n",
        "\n",
        "id_of_ckpt_to_use = -1 # 推論に使用するチェックポイントのID（前のセルの出力に対応）。\n",
        "                        # デフォルト値の-1は, 上記のチェックポイントのリストの中で \"最後から2番目 \"のチェックポイントを指します.\n",
        "                        # 他のチェックポイントを選択したい場合は, -1をリストにあるチェックポイントIDのどれかに変更します.\n",
        "\n",
        "ckpt_name = os.path.join(ckpt_dir, ckpts[id_of_ckpt_to_use])\n",
        "\n",
        "\"\"\" デコード・パラメータを変更する必要があるかもしれないが、必ずしも必要ではない。 \"\"\"\n",
        "\n",
        "# ここでデコードパラメータを調整することができます。デコードパラメータの詳細な説明については、宿題のスライドを参照してください。\n",
        "max_len = 128 # 生成される返信の最大長。\n",
        "temperature = 0.1 # 生成される返信のランダム性を設定。値が小さいほど返信が安定する。\n",
        "top_p = 0.3 # top-p(核)サンプリングのしきい値.\n",
        "# top_k = 5 # top-kの値を調整することで、生成される返答の多様性を高め、繰り返し単語が 生成されないようにする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTr0DfVBSekD"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルト設定を使用した場合、約2分**かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "-wKVPpMVtkql"
      },
      "outputs": [],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "test_data_path = \"/content/dataset/Tang_testingdata_ja.json\"\n",
        "output_path = os.path.join(output_dir, \"results.txt\")\n",
        "\n",
        "cache_dir = \"./cache\" # キャッシュディレクトリのパスを設定する.\n",
        "seed = 42 # 結果を再現するためのランダムシードを設定する。\n",
        "no_repeat_ngram_size = 3 # 重複セグメントを生成しないように、no-repeat ngramのサイズを設定する。\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# トークン化器を使用して、モデル名をモデルが読み取り可能な数値表現に変換します。\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    cache_dir=cache_dir,\n",
        "    quantization_config=nf4_config\n",
        ")\n",
        "\n",
        "# 事前学習モデルからモデルをロードし、8ビット整数(INT8)モデルとして設定する。\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=nf4_config,\n",
        "    device_map={'': 0},  # 設定使用的設備，此處指定為 GPU 0\n",
        "    cache_dir=cache_dir\n",
        ")\n",
        "\n",
        "# 指定したチェックポイントからモデルの重みをロードする\n",
        "model = PeftModel.from_pretrained(model, ckpt_name, device_map={'': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs4_EtnoWA5b"
      },
      "source": [
        "以下のコードブロックの実行時間は、デフォルト設定を使用した場合、約 **4**分かかりますが、Colabの状態によって異なる場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xcHoU2X8xRkn",
        "outputId": "0125ca14-71b3-460c-e351-d317bad655c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 雪が晴れて銀の衣装を纏い、素朴な景色が広がる。橘の木は高くそびえ、瓊の枝に映える。 ★★★ 雲は白い雲を覆い、風は青空を覆う。白い花は青い葉を覆し、紅の花は紅葉を隠す。遠くの山は青く青く、遠くに山は白く白く。遠い山は遠く、山は山に隠れる。 一時、遠い雲は青雲を巻き、遠しに山の影は白雲を隣す。 雁は遠い空に飛び、鶯は遠しの\n",
            "2. 夫子は何を為す者ぞ？一代の中にひたすらに暮らす。 ★★★ 一朝の春を望み、二月の花を賞す。三日の雨は散り、四月の風は散る。五日は晴れ、六月は晴らかに。七日は雨、八月は雨。九日は花、十日は草。一朝は花の色、二日は葉の色。三朝は草の色，四朝は葉。五朝は風の色六朝は雨の色。 一夕の花の香、二朝の葉の香。三夕の雨の\n",
            "3. 飛び蓋は芳園を去り、蘭は翠渚を遊ぶ。 ★★★ 雲は青空を覆い、風は碧空を舞う。花は芳草を覆う、草は芳華を覆す。芳華は芳菲を含み、芳菲は芳华を含む。芳菲の花は青の園に咲き、芳華の草は碧の渚に咗る。 一朝の芳華、二日の芳菲。芳華と芳菲、芳園と芳渚。 青の園を覆る花、碧の草を遊\n",
            "4. 風が節句を告げて吹き始め、灰色の律動が初陽とともに動き出す。 ★★★ 雲はまだ晴れ、風はまだ明るく。草はまだ青い、鳥はまだ飛ぶ。草の葉はまだ開き、鳥の羽はまだ羽を伸ばす。草木はまだ生きて、鳥鶯はまだ鳴き続ける。 今や春の花を賞し、春の鳥を観察する。 雁はまだ飛び、鶲は飛び、鳥が飛び、魚が飛び。鶏はまだ鶴の下に飛び、�\n",
            "5. 昨夜の星辰、昨夜の風  \n",
            "画楼の西、桂堂の東 ★★★ 雲は夜に散り、月は明るく照る。  \n",
            "人を驚かすと、人を喜ぶと。  \n",
            "夜の月は遠く、人は遠い。  \n",
            "遠くの月、遠くに人を望みる。  \n",
            "（夜の明るさは遠かに散る、月の明かりは遠きに照る）  \n",
            "人は驚き、人びて喜び。夜の雲は散り散りして、月明るい。 人を惊かす、\n",
            "6. 三日厨に入り、手を洗い、羹と湯を作る。 ★★★ 雲は散り、風は散る。草は枯れ、花は枯らす。鳥は散らばる、鳥は飛ぶ。鳥の羽は散った、鳥の翼は散れ、鳥が散らぶ。草の葉は枯れる、花の葉も枯れる。鳥が飛ぶと、鳥を散らす。 また、鳥も飛ぶ。 雁は散らず、鶯は散らない。鶓は散られ、鷹は散れる。</s\n",
            "7. 嵩山の雲、秦の樹、長く離れ住む  \n",
            "双鯉、遠く遠く、一通の手紙 ★★★ 雲は山の上に散り、風は山に散らばる。  \n",
            "遠くの山は、遠いと見える。  \n",
            "雲は山を覆い、風が山を散らす。  \n",
            "鯨は遠くに散る。 雁は遠い山に寄り、鷹は遠しに寄る。 一縁の鯫は遠山に住む。 山の上は雲を覆う。遠く山の下に寄らし、\n",
            "8. 慨然として長剣を撫で、世を救うは名を邀わざるなり。 ★★★ 長剣は長く、剣の長さは長し、剤は剣に似る。剣が長く長く剣と似る、剰りは剤の長く似る。 一時、長削を撃ち、削は削り、剑は剑り。 长剣、長くは長き、剎は剎に似た。長剎、長き長く。\n",
            "長剠は長剤、\n",
            "9. 南遊に乗じて戒厳を忘れず、九重の誰が諫書を省みるだろうか。 ★★★ 一朝の春を望み、二月の花を賞す。春の花はまだ未だ開き、花はまた閉じて帰る。春を待つと、花を閉じる。花は閉じ、花の閉じは閉き、閉じた花は開きる。 一時、花が閉じられ、二度、花を開く。 花は閉まり、花も閉じられる。花は花を咲かせる。\n",
            "花は咲き、�\n",
            "10. 猿鳥さえも簡書を恐れて躊躇し、風雲は常に護儲胥のために動く。 ★★★ 雲は深く散り、風は急く散る。雲は山の上に散り散りして、風が山の下に散る。 今や山の道は遠く、遠くに山の路は遠い。 雁は遠かに飛ぶ、鶯は遠きに飛び。遠くの山は遠し、遠い道は長く。\n",
            "遠く山の峰は遠くなり、遠き道は広く。</ｓ> 道は遠\n",
            "11. 君に帰る日を尋ねても、まだ定まらない。巴山の夜雨が秋の池を満たしている。 ★★★ 雲は夜に散り、風は晴れに吹き去る。山の影は遠くに広がる、水は深く流る。遠くの山はまだ夜に静かに見える。遠い道はまだ山の下に座く、遠くはまだ池の上に度る。 一朝に山の道を渡る、二日には池の水を渡す。 雁は夜の池に寄る、鶯は夜を渡り、鴻は夜\n",
            "12. 会う時難く別るも亦難し、東風無力して百花殘る。 ★★★ 花はまだ残り、草はまだ生じる。春の花はまだ開き、秋の花もまだ閉じる。 一朝の花を閉じて、二朝の草を生じて。 芍はまだ花を咲かず、草の花がまだ花を開き。花は残りの花、草が生じた草。. 一時花は閉じ、草も生じ。. 気はまだ空しく、花はまた閉じ\n",
            "13. 雲母の屏風に燭影深く、長河は次第に落ちて晓星沈む。 ★★★ 雲は夜に散り、月は明るく照る。雲は夜の空に散らばる、月の光は明かりに照る。 今夜の月はまだ明るい。雲は散らぎ、月が照る。今夜は月明るくなる。 雁は夜明るさに飛ぶ。. 雨は夜空に降り、雲は夕陽に覆う。. 水は夜を覆い、雲が\n",
            "14. 高閣に客去りぬ、小園に花乱れて飛ぶ。 ★★★ 高台の外に客が帰る、小园の花が飛ぶ。遠く遠く、遠くに遠く。遠い遠い、遠い。遠遠くの遠い。 一時、遠遠いの遠く。遠くは遠く、遠し遠し。 高遠に遠し、遠々に遠々。. 高い高い、高遠。. 花は遠い花、遠か。, 芹は遠かの\n",
            "15. 瑶池阿母の華麗な窓が開き、黄竹の歌声が地を震わせて哀しみを誘う。 ★★★ 雲は青空に散り、風は碧空に舞う。玉の衣を揺らし、玉の馬を駆り、玉は玉の車を駕す。玉は車を停めて、玉を駅に置き、玉が車を乗る。 一朝に玉の马を駄めて、二日に玉を車に乗せる。 玉の馬は車に駆られ、玉車は車に乗る。</p> 珍しく玉の騎馬を乗せて、\n"
          ]
        }
      ],
      "source": [
        "\"\"\" このセルでコードを変更しないことを推奨します。 \"\"\"\n",
        "\n",
        "results = []\n",
        "\n",
        "# ランダム性、ビームサーチ、その他の関連パラメータを含む生成コンフィギュレーションを設定する。\n",
        "generation_config = GenerationConfig(\n",
        "    do_sample=True,\n",
        "    temperature=temperature,\n",
        "    num_beams=1,\n",
        "    top_p=top_p,\n",
        "    # top_k=top_k,\n",
        "    no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "    pad_token_id=2\n",
        ")\n",
        "\n",
        "# テストデータの読み込み\n",
        "with open(test_data_path, \"r\", encoding = \"utf-8\") as f:\n",
        "    test_datas = json.load(f)\n",
        "\n",
        "# 各テストデータに対して予測を行い、結果を保存する。\n",
        "with open(output_path, \"w\", encoding = \"utf-8\") as f:\n",
        "  for (i, test_data) in enumerate(test_datas):\n",
        "      predict = evaluate(test_data[\"instruction\"], generation_config, max_len, test_data[\"input\"], verbose = False)\n",
        "      f.write(f\"{i+1}. {test_data['input']} ★★★ {predict}\\n\")\n",
        "      print(f\"{i+1}. {test_data['input']} ★★★ {predict}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tJT1WINKXV7"
      },
      "source": [
        "## **重要なこと**： 15個の唐詩の結果を提出 .\n",
        "これらの唐詩の結果は \"/content/dataset/results.txt \"にあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT78LeWaJM4D"
      },
      "source": [
        "## ファインチューニング・モデルとファインチューニングなしのモデルの比較をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx_mZZAZWdiE"
      },
      "source": [
        "ここで、上の「微調整前の推論」で見たのと同じ例で、我々のモデルがどのようなことができるかをチェックする。\n",
        "\n",
        "以下のコードブロックの実行時間は、デフォルトの設定であれば**40**秒程度ですが、Colabの状態によって異なるかもしれません。ここで、上の「微調整前の推論」で見たのと同じ例で、我々のモデルがどのようなことができるかをチェックする。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BtDG2WhIWZlS",
        "outputId": "86f257bf-3d19-4d52-a3a7-f526468032a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。\n",
            "\n",
            "会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。\n",
            "\n",
            "モデル出力:\n",
            "花は散らばる、風は散る。花は散り、風が散る。 一朝に散らし、二朝にまた散らす。. 一夕に散り，二夕にまた。. 芹の花はまだ散らされ、花の色はまだ残る。</p> また、花が散らされて、花を散らして。</p>. また花が残る、花も散らされる。</p> 気は散らず、花散らかし。</\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。\n",
            "\n",
            "重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。\n",
            "\n",
            "モデル出力:\n",
            "重い帳は重い、帳は帳、帳の下に重い。 深く哀しみ、哀しき。 水は深く、水は深い。 長く夜、夜は深き。 極めて哀しこらん、哀しむ。 重く帳の上に、帳が重く、帳も重く。帳は深し、帳、深く。</c> 淡い帳、深い帳。 楕は重く重く長く。</\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3:\n",
            "モデル入力:\n",
            "以下は唐詩の一行目である。 あなたの知識で判断し、唐詩を簡潔に完成しなさい。\n",
            "\n",
            "逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。\n",
            "\n",
            "モデル出力:\n",
            "雲は深く散り、風は遠く散る。  \n",
            "遠くの山は青い、  \n",
            "遠いの川は碧く。  \n",
            "人を驚かすと、  \n",
            "人びて驚く。  \n",
            "（この唐詩は、唐の詩人の名前を書かず、繁体字を翻訳し、繁體字の字を繁体語に翻証し、翻訕し、誤りを避けるために書かれたものである。）  \n",
            "（繁体文字の字は、繁華の書体を翻\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# test demo examples\n",
        "test_tang_list = ['会っても別れを告げるのは難しい，東風には力がなく、花はすべて散ってしまった。',\n",
        "                  '重いカーテンの下で、深い喪に服していた，横になってからの夜は長く、澄んでいる。',\n",
        "                  '逃亡の果てに追いかける香りの星，禁断の園は驚きに満ちている。']\n",
        "\n",
        "# get the model output for each examples\n",
        "demo_before_finetune = []\n",
        "for tang in test_tang_list:\n",
        "  demo_before_finetune.append(f'モデル入力:\\n{system_prompt}\\n\\n{tang}\\n\\nモデル出力:\\n'+evaluate(system_prompt, generation_config, max_len, tang, verbose = False))\n",
        "\n",
        "# print and store the output to text file\n",
        "for idx in range(len(demo_before_finetune)):\n",
        "  print(f\"Example {idx + 1}:\")\n",
        "  print(demo_before_finetune[idx])\n",
        "  print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wagFeDX4Hpa8"
      },
      "source": [
        "## **重要**： 上記の3つの例は提出しないでください。\n",
        "この3つの例は、微調整前と微調整後のモデルのパフォーマンスを比較するためだけに使用されます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWgTS13bgnWQ"
      },
      "source": [
        "## 結果のあなたのPCにダウンロードします（ダウンロードフォルダにresult.txtファイル）\n",
        "宿題を終わらせるには、このファイルが必要です。 ブラウザが自動的にダウンロードしない場合は、Google Driveにあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "rUDuNQOY4os_",
        "outputId": "bed28e74-173c-4535-c7ca-44a72c48625e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3340f35e-aaf1-495d-9ce8-db86d4819e40\", \"results.txt\", 6493)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(output_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec3751ef70574744a40e92066cf0bbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78000f7ce8334836a9403c837d687389",
              "IPY_MODEL_50f2b266aab54e27b291ba8dfaad9eef",
              "IPY_MODEL_80af4447e8494264898c5d7b924f45fa"
            ],
            "layout": "IPY_MODEL_8d3b8fe057f647839e7f24e0c16f3bcd"
          }
        },
        "78000f7ce8334836a9403c837d687389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f263c062d344e69f9d8fc86d9b99bc",
            "placeholder": "​",
            "style": "IPY_MODEL_d94a94cb45b94e7f86b2fe282f97ee6e",
            "value": "Generating train split: "
          }
        },
        "50f2b266aab54e27b291ba8dfaad9eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af14d45902a418297e5cc6597a70416",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c96c10ab79f467b805031f9c7e7b606",
            "value": 1
          }
        },
        "80af4447e8494264898c5d7b924f45fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2ced1e122fd498a83d914d88ab5d7c0",
            "placeholder": "​",
            "style": "IPY_MODEL_61fbca90c2fe4b0f97dfffc928d8e6bd",
            "value": " 1040/0 [00:00&lt;00:00, 28428.18 examples/s]"
          }
        },
        "8d3b8fe057f647839e7f24e0c16f3bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f263c062d344e69f9d8fc86d9b99bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94a94cb45b94e7f86b2fe282f97ee6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af14d45902a418297e5cc6597a70416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4c96c10ab79f467b805031f9c7e7b606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2ced1e122fd498a83d914d88ab5d7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fbca90c2fe4b0f97dfffc928d8e6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808987d651a94d9095e2cf493d2a6847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df82c367019c4bfc922bd113b29e3540",
              "IPY_MODEL_eb14bc21ef114edfad0e883e415c0cb8",
              "IPY_MODEL_b8c8b1ae852942af8ef14b41dd57c728"
            ],
            "layout": "IPY_MODEL_2acc8ad702fb497cbb403416f9f4ebe0"
          }
        },
        "df82c367019c4bfc922bd113b29e3540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0158f0ab5d754dcda0b87fc34d1c0145",
            "placeholder": "​",
            "style": "IPY_MODEL_5f4bc408d3bb42c2b8f2941585aa2ad6",
            "value": "Map: 100%"
          }
        },
        "eb14bc21ef114edfad0e883e415c0cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e19afb0f424c41c3ada46f8953d355ab",
            "max": 1040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e286e3729d954ce99f626bbbd1815ff0",
            "value": 1040
          }
        },
        "b8c8b1ae852942af8ef14b41dd57c728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3688c2b88e04cd38382dd684a16381b",
            "placeholder": "​",
            "style": "IPY_MODEL_e5f239e73ebf480db670779196d12d69",
            "value": " 1040/1040 [00:01&lt;00:00, 727.46 examples/s]"
          }
        },
        "2acc8ad702fb497cbb403416f9f4ebe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0158f0ab5d754dcda0b87fc34d1c0145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4bc408d3bb42c2b8f2941585aa2ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e19afb0f424c41c3ada46f8953d355ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e286e3729d954ce99f626bbbd1815ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3688c2b88e04cd38382dd684a16381b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f239e73ebf480db670779196d12d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}